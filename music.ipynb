{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import traceback\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import IPython\n",
    "import pickle\n",
    "\n",
    "\n",
    "seed_int=666\n",
    "list_all_midi = glob.glob(\"C:/Users/VARNA/Desktop/composser/midi/*.midi\")\n",
    "random.shuffle(list_all_midi)\n",
    "#print(len(list_all_midi))\n",
    "sample_midi = list_all_midi[0:100]  \n",
    "#print(sample_midi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing MIDI files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoteTokenizer:\n",
    "    \n",
    "    def __init__(self):\n",
    "      self.notes_to_index = {}\n",
    "      self.index_to_notes = {}\n",
    "      self.num_of_word = 0\n",
    "      self.unique_word = 0\n",
    "      self.notes_freq = {}\n",
    "        \n",
    "    def transform(self,list_array):\n",
    "      \"\"\" Transform a list of note in string into index.\n",
    "      \n",
    "      Parameters\n",
    "      ==========\n",
    "      list_array : list\n",
    "        list of note in string format\n",
    "      \n",
    "      Returns\n",
    "      =======\n",
    "      The transformed list in numpy array.\n",
    "      \n",
    "      \"\"\"\n",
    "      transformed_list = []\n",
    "      for instance in list_array:\n",
    "          transformed_list.append([self.notes_to_index[note] for note in instance])\n",
    "      return np.array(transformed_list, dtype=np.int32)\n",
    " \n",
    "    def partial_fit(self, notes):\n",
    "        \"\"\" Partial fit on the dictionary of the tokenizer\n",
    "        \n",
    "        Parameters\n",
    "        ==========\n",
    "        notes : list of notes\n",
    "        \n",
    "        \"\"\"\n",
    "        for note in notes:\n",
    "            note_str = ','.join(str(a) for a in note)\n",
    "            if note_str in self.notes_freq:\n",
    "                self.notes_freq[note_str] += 1\n",
    "                self.num_of_word += 1\n",
    "            else:\n",
    "                self.notes_freq[note_str] = 1\n",
    "                self.unique_word += 1\n",
    "                self.num_of_word += 1\n",
    "                self.notes_to_index[note_str], self.index_to_notes[self.unique_word] = self.unique_word, note_str\n",
    "            \n",
    "    def add_new_note(self, note):\n",
    "        \"\"\" Add a new note into the dictionary\n",
    "\n",
    "        Parameters\n",
    "        ==========\n",
    "        note : str\n",
    "          a new note who is not in dictionary.  \n",
    "\n",
    "        \"\"\"\n",
    "        assert note not in self.notes_to_index\n",
    "        self.unique_word += 1\n",
    "        self.notes_to_index[note], self.index_to_notes[self.unique_word] = self.unique_word, note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dict_time_notes(list_all_midi, batch_song = 16, start_index=0, fs=30, use_tqdm=True):\n",
    "    \"\"\" Generate map (dictionary) of music ( in index ) to piano_roll (in np.array)\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    list_all_midi : list\n",
    "        List of midi files\n",
    "    batch_music : int\n",
    "      A number of music in one batch\n",
    "    start_index : int\n",
    "      The start index to be batched in list_all_midi\n",
    "    fs : int\n",
    "      Sampling frequency of the columns, i.e. each column is spaced apart\n",
    "        by ``1./fs`` seconds.\n",
    "    use_tqdm : bool\n",
    "      Whether to use tqdm or not in the function\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    dictionary of music to piano_roll (in np.array)\n",
    "\n",
    "    \"\"\"\n",
    "    assert len(list_all_midi) >= batch_song\n",
    "    \n",
    "    dict_time_notes = {}\n",
    "    process_tqdm_midi = tqdm_notebook(range(start_index, min(start_index + batch_song, len(list_all_midi)))) if use_tqdm else range(start_index,  min(start_index + batch_song, len(list_all_midi)))\n",
    "    for i in process_tqdm_midi:\n",
    "        midi_file_name = list_all_midi[i]\n",
    "        if use_tqdm:\n",
    "            process_tqdm_midi.set_description(\"Processing {}\".format(midi_file_name))\n",
    "        try: # Handle exception on malformat MIDI files\n",
    "            midi_pretty_format = pretty_midi.PrettyMIDI(midi_file_name)\n",
    "            piano_midi = midi_pretty_format.instruments[0] # Get the piano channels\n",
    "            piano_roll = piano_midi.get_piano_roll(fs=fs)\n",
    "            dict_time_notes[i] = piano_roll\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"broken file : {}\".format(midi_file_name))\n",
    "            pass\n",
    "    return dict_time_notes\n",
    "\n",
    "def generate_input_and_target(dict_keys_time, seq_len=50):\n",
    "    \"\"\" Generate input and the target of our deep learning for one music.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    dict_keys_time : dict\n",
    "      Dictionary of timestep and notes\n",
    "    seq_len : int\n",
    "      The length of the sequence\n",
    "      \n",
    "    Returns\n",
    "    =======\n",
    "    Tuple of list of input and list of target of neural network.\n",
    "    \n",
    "       \n",
    "    \"\"\"\n",
    "    # Get the start time and end time\n",
    "    start_time, end_time = list(dict_keys_time.keys())[0], list(dict_keys_time.keys())[-1]\n",
    "    list_training, list_target = [], []\n",
    "    for index_enum, time in enumerate(range(start_time, end_time)):\n",
    "        list_append_training, list_append_target = [], []\n",
    "        start_iterate = 0\n",
    "        flag_target_append = False # flag to append the test list\n",
    "        if index_enum < seq_len:\n",
    "            start_iterate = seq_len - index_enum - 1\n",
    "            for i in range(start_iterate): # add 'e' to the seq list. \n",
    "                list_append_training.append('e')\n",
    "                flag_target_append = True\n",
    "\n",
    "        for i in range(start_iterate,seq_len):\n",
    "            index_enum = time - (seq_len - i - 1)\n",
    "            if index_enum in dict_keys_time:\n",
    "                list_append_training.append(','.join(str(x) for x in dict_keys_time[index_enum]))      \n",
    "            else:\n",
    "                list_append_training.append('e')\n",
    "\n",
    "        # add time + 1 to the list_append_target\n",
    "        if time+1 in dict_keys_time:\n",
    "            list_append_target.append(','.join(str(x) for x in dict_keys_time[time+1]))\n",
    "        else:\n",
    "            list_append_target.append('e')\n",
    "        list_training.append(list_append_training)\n",
    "        list_target.append(list_append_target)\n",
    "    return list_training, list_target\n",
    "\n",
    "def process_notes_in_song(dict_time_notes, seq_len = 50):\n",
    "    \"\"\"\n",
    "    Iterate the dict of piano rolls into dictionary of timesteps and note played\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    dict_time_notes : dict\n",
    "      dict contains index of music ( in index ) to piano_roll (in np.array)\n",
    "    seq_len : int\n",
    "      Length of the sequence\n",
    "      \n",
    "    Returns\n",
    "    =======\n",
    "    Dict of timesteps and note played\n",
    "    \"\"\"\n",
    "    list_of_dict_keys_time = []\n",
    "    \n",
    "    for key in dict_time_notes:\n",
    "        sample = dict_time_notes[key]\n",
    "        times = np.unique(np.where(sample > 0)[1])\n",
    "        index = np.where(sample > 0)\n",
    "        dict_keys_time = {}\n",
    "\n",
    "        for time in times:\n",
    "            index_where = np.where(index[1] == time)\n",
    "            notes = index[0][index_where]\n",
    "            dict_keys_time[time] = notes\n",
    "        list_of_dict_keys_time.append(dict_keys_time)\n",
    "    return list_of_dict_keys_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a372ae55327f46f9a2d604ffa8ee0ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = 1\n",
    "start_index = 0\n",
    "note_tokenizer = NoteTokenizer()\n",
    "#tqdm is used for showing the progress bars\n",
    "for i in tqdm_notebook(range(len(sample_midi))):\n",
    "    dict_time_notes = generate_dict_time_notes(sample_midi, batch_song=1, start_index=i, use_tqdm=False, fs=5)\n",
    "    full_notes = process_notes_in_song(dict_time_notes)\n",
    "    #print(full_notes)\n",
    "    for note in full_notes:\n",
    "        note_tokenizer.partial_fit(list(note.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38634\n"
     ]
    }
   ],
   "source": [
    "note_tokenizer.add_new_note('e')\n",
    "unique_notes = note_tokenizer.unique_word\n",
    "print(unique_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "The architecture is as follow:\n",
    "1. Embedding(used as only first layer.to convert to 2D to 3D)\n",
    "2. LSTM\n",
    "3. Self Head Attention\n",
    "4. LSTM\n",
    "5. Self Head Attention\n",
    "6. Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 50\n",
    "EPOCHS = 4\n",
    "BATCH_SONG = 16\n",
    "BATCH_NNET_SIZE = 96\n",
    "TOTAL_SONGS = len(sample_midi)\n",
    "FRAME_PER_SECOND = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqSelfAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    ATTENTION_TYPE_ADD = 'additive'\n",
    "    ATTENTION_TYPE_MUL = 'multiplicative'\n",
    "\n",
    "    def __init__(self,\n",
    "                 units=32,\n",
    "                 attention_width=None,\n",
    "                 attention_type=ATTENTION_TYPE_ADD,\n",
    "                 return_attention=False,\n",
    "                 history_only=False,\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 use_additive_bias=True,\n",
    "                 use_attention_bias=True,\n",
    "                 attention_activation=None,\n",
    "                 attention_regularizer_weight=0.0,\n",
    "                 **kwargs):\n",
    "        \"\"\"Layer initialization.\n",
    "        For additive attention, see: https://arxiv.org/pdf/1806.01264.pdf\n",
    "        :param units: The dimension of the vectors that used to calculate the attention weights.\n",
    "        :param attention_width: The width of local attention.\n",
    "        :param attention_type: 'additive' or 'multiplicative'.\n",
    "        :param return_attention: Whether to return the attention weights for visualization.\n",
    "        :param history_only: Only use historical pieces of data.\n",
    "        :param kernel_initializer: The initializer for weight matrices.\n",
    "        :param bias_initializer: The initializer for biases.\n",
    "        :param kernel_regularizer: The regularization for weight matrices.\n",
    "        :param bias_regularizer: The regularization for biases.\n",
    "        :param kernel_constraint: The constraint for weight matrices.\n",
    "        :param bias_constraint: The constraint for biases.\n",
    "        :param use_additive_bias: Whether to use bias while calculating the relevance of inputs features\n",
    "                                  in additive mode.\n",
    "        :param use_attention_bias: Whether to use bias while calculating the weights of attention.\n",
    "        :param attention_activation: The activation used for calculating the weights of attention.\n",
    "        :param attention_regularizer_weight: The weights of attention regularizer.\n",
    "        :param kwargs: Parameters for parent class.\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.units = units\n",
    "        self.attention_width = attention_width\n",
    "        self.attention_type = attention_type\n",
    "        self.return_attention = return_attention\n",
    "        self.history_only = history_only\n",
    "        if history_only and attention_width is None:\n",
    "            self.attention_width = int(1e9)\n",
    "\n",
    "        self.use_additive_bias = use_additive_bias\n",
    "        self.use_attention_bias = use_attention_bias\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = tf.keras.initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = tf.keras.regularizers.get(bias_regularizer)\n",
    "        self.kernel_constraint = tf.keras.constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = tf.keras.constraints.get(bias_constraint)\n",
    "        self.attention_activation = tf.keras.activations.get(attention_activation)\n",
    "        self.attention_regularizer_weight = attention_regularizer_weight\n",
    "        self._backend = tf.keras.backend.backend()\n",
    "\n",
    "        if attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            self.Wx, self.Wt, self.bh = None, None, None\n",
    "            self.Wa, self.ba = None, None\n",
    "        elif attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            self.Wa, self.ba = None, None\n",
    "        else:\n",
    "            raise NotImplementedError('No implementation for attention type : ' + attention_type)\n",
    "\n",
    "        super(SeqSelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'attention_width': self.attention_width,\n",
    "            'attention_type': self.attention_type,\n",
    "            'return_attention': self.return_attention,\n",
    "            'history_only': self.history_only,\n",
    "            'use_additive_bias': self.use_additive_bias,\n",
    "            'use_attention_bias': self.use_attention_bias,\n",
    "            'kernel_initializer': tf.keras.regularizers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': tf.keras.regularizers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': tf.keras.regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': tf.keras.regularizers.serialize(self.bias_regularizer),\n",
    "            'kernel_constraint': tf.keras.constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': tf.keras.constraints.serialize(self.bias_constraint),\n",
    "            'attention_activation': tf.keras.activations.serialize(self.attention_activation),\n",
    "            'attention_regularizer_weight': self.attention_regularizer_weight,\n",
    "        }\n",
    "        base_config = super(SeqSelfAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            self._build_additive_attention(input_shape)\n",
    "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            self._build_multiplicative_attention(input_shape)\n",
    "        super(SeqSelfAttention, self).build(input_shape)\n",
    "\n",
    "    def _build_additive_attention(self, input_shape):\n",
    "        feature_dim = input_shape[2]\n",
    "\n",
    "        self.Wt = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                  name='{}_Add_Wt'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        self.Wx = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                  name='{}_Add_Wx'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_additive_bias:\n",
    "            self.bh = self.add_weight(shape=(self.units,),\n",
    "                                      name='{}_Add_bh'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "        self.Wa = self.add_weight(shape=(self.units, 1),\n",
    "                                  name='{}_Add_Wa'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_attention_bias:\n",
    "            self.ba = self.add_weight(shape=(1,),\n",
    "                                      name='{}_Add_ba'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "    def _build_multiplicative_attention(self, input_shape):\n",
    "        feature_dim = input_shape[2]\n",
    "\n",
    "        self.Wa = self.add_weight(shape=(feature_dim, feature_dim),\n",
    "                                  name='{}_Mul_Wa'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_attention_bias:\n",
    "            self.ba = self.add_weight(shape=(1,),\n",
    "                                      name='{}_Mul_ba'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "    def call(self, inputs, mask=None, **kwargs):\n",
    "        if isinstance(inputs, list):\n",
    "            inputs, positions = inputs\n",
    "            positions = K.cast(positions, 'int32')\n",
    "            mask = mask[1]\n",
    "        else:\n",
    "            positions = None\n",
    "\n",
    "        input_len = K.shape(inputs)[1]\n",
    "\n",
    "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            e = self._call_additive_emission(inputs)\n",
    "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            e = self._call_multiplicative_emission(inputs)\n",
    "\n",
    "        if self.attention_activation is not None:\n",
    "            e = self.attention_activation(e)\n",
    "        e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
    "        if self.attention_width is not None:\n",
    "            ones = tf.ones((input_len, input_len))\n",
    "            if self.history_only:\n",
    "                local = tf.linalg.band_part(\n",
    "                    ones,\n",
    "                    K.minimum(input_len, self.attention_width - 1),\n",
    "                    0,\n",
    "                )\n",
    "            else:\n",
    "                local = tf.linalg.band_part(\n",
    "                    ones,\n",
    "                    K.minimum(input_len, self.attention_width // 2),\n",
    "                    K.minimum(input_len, (self.attention_width - 1) // 2),\n",
    "                )\n",
    "            e = e * K.expand_dims(local, 0)\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            mask = K.expand_dims(mask)\n",
    "            e = K.permute_dimensions(K.permute_dimensions(e * mask, (0, 2, 1)) * mask, (0, 2, 1))\n",
    "\n",
    "        # a_{t} = \\text{softmax}(e_t)\n",
    "        s = K.sum(e, axis=-1)\n",
    "        s = K.tile(K.expand_dims(s, axis=-1), K.stack([1, 1, input_len]))\n",
    "        a = e / (s + K.epsilon())\n",
    "\n",
    "        # l_t = \\sum_{t'} a_{t, t'} x_{t'}\n",
    "        v = K.batch_dot(a, inputs)\n",
    "        if self.attention_regularizer_weight > 0.0:\n",
    "            self.add_loss(self._attention_regularizer(a))\n",
    "\n",
    "        if positions is not None:\n",
    "            pos_num = K.shape(positions)[1]\n",
    "            batch_indices = K.tile(K.expand_dims(K.arange(K.shape(inputs)[0]), axis=-1), K.stack([1, pos_num]))\n",
    "            pos_indices = K.stack([batch_indices, positions], axis=-1)\n",
    "            v = tf.gather_nd(v, pos_indices)\n",
    "            a = tf.gather_nd(a, pos_indices)\n",
    "\n",
    "        if self.return_attention:\n",
    "            return [v, a]\n",
    "        return v\n",
    "\n",
    "    def _call_additive_emission(self, inputs):\n",
    "        input_shape = K.shape(inputs)\n",
    "        batch_size, input_len = input_shape[0], input_shape[1]\n",
    "\n",
    "        # h_{t, t'} = \\tanh(x_t^T W_t + x_{t'}^T W_x + b_h)\n",
    "        q, k = K.dot(inputs, self.Wt), K.dot(inputs, self.Wx)\n",
    "        q = K.tile(K.expand_dims(q, 2), K.stack([1, 1, input_len, 1]))\n",
    "        k = K.tile(K.expand_dims(k, 1), K.stack([1, input_len, 1, 1]))\n",
    "        if self.use_additive_bias:\n",
    "            h = K.tanh(q + k + self.bh)\n",
    "        else:\n",
    "            h = K.tanh(q + k)\n",
    "\n",
    "        # e_{t, t'} = W_a h_{t, t'} + b_a\n",
    "        if self.use_attention_bias:\n",
    "            e = K.reshape(K.dot(h, self.Wa) + self.ba, (batch_size, input_len, input_len))\n",
    "        else:\n",
    "            e = K.reshape(K.dot(h, self.Wa), (batch_size, input_len, input_len))\n",
    "        return e\n",
    "\n",
    "    def _call_multiplicative_emission(self, inputs):\n",
    "        # e_{t, t'} = x_t^T W_a x_{t'} + b_a\n",
    "        e = K.batch_dot(K.dot(inputs, self.Wa), K.permute_dimensions(inputs, (0, 2, 1)))\n",
    "        if self.use_attention_bias:\n",
    "            e = e + self.ba\n",
    "        return e\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape, pos_shape = input_shape\n",
    "            output_shape = (input_shape[0], pos_shape[1], input_shape[2])\n",
    "        else:\n",
    "            output_shape = input_shape\n",
    "        if self.return_attention:\n",
    "            attention_shape = (input_shape[0], output_shape[1], input_shape[1])\n",
    "            return [output_shape, attention_shape]\n",
    "        return output_shape\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if isinstance(inputs, list):\n",
    "            mask = mask[1]\n",
    "        if self.return_attention:\n",
    "            return [mask, None]\n",
    "        return mask\n",
    "\n",
    "    def _attention_regularizer(self, attention):\n",
    "        batch_size = K.cast(K.shape(attention)[0], K.floatx())\n",
    "        input_len = K.shape(attention)[-1]\n",
    "        return self.attention_regularizer_weight * K.sum(K.square(K.batch_dot(\n",
    "            attention,\n",
    "            K.permute_dimensions(attention, (0, 2, 1))) - tf.eye(input_len))) / batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def get_custom_objects():\n",
    "      return {'SeqSelfAttention': SeqSelfAttention}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(seq_len, unique_notes, dropout=0.3, output_emb=100, rnn_unit=128, dense_unit=64):\n",
    "  inputs = tf.keras.layers.Input(shape=(seq_len,))\n",
    "  embedding = tf.keras.layers.Embedding(input_dim=unique_notes+1, output_dim=output_emb, input_length=seq_len)(inputs)\n",
    "  forward_pass = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_unit, return_sequences=True))(embedding)\n",
    "  forward_pass , att_vector = SeqSelfAttention(\n",
    "      return_attention=True,\n",
    "      attention_activation='sigmoid', \n",
    "      attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "      attention_width=50, \n",
    "      kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "      bias_regularizer=tf.keras.regularizers.l1(1e-4),\n",
    "      attention_regularizer_weight=1e-4,\n",
    "  )(forward_pass)\n",
    "  forward_pass = tf.keras.layers.Dropout(dropout)(forward_pass)\n",
    "  forward_pass = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_unit, return_sequences=True))(forward_pass)\n",
    "  forward_pass , att_vector2 = SeqSelfAttention(\n",
    "      return_attention=True,\n",
    "      attention_activation='sigmoid', \n",
    "      attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "      attention_width=50, \n",
    "      kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "      bias_regularizer=tf.keras.regularizers.l1(1e-4),\n",
    "      attention_regularizer_weight=1e-4,\n",
    "  )(forward_pass)\n",
    "  forward_pass = tf.keras.layers.Dropout(dropout)(forward_pass)\n",
    "  forward_pass = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_unit))(forward_pass)\n",
    "  forward_pass = tf.keras.layers.Dropout(dropout)(forward_pass)\n",
    "  forward_pass = tf.keras.layers.Dense(dense_unit)(forward_pass)\n",
    "  forward_pass = tf.keras.layers.LeakyReLU()(forward_pass)\n",
    "  outputs = tf.keras.layers.Dense(unique_notes+1, activation = \"softmax\")(forward_pass)\n",
    "\n",
    "  model = tf.keras.Model(inputs=inputs, outputs=outputs, name='generate_scores_rnn')\n",
    "  return model\n",
    "\n",
    "model = create_model(seq_len, unique_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generate_scores_rnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 50, 100)           3863500   \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 50, 256)           176640    \n",
      "_________________________________________________________________\n",
      "seq_self_attention_3 (SeqSel [(None, 50, 256), (None,  65537     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 50, 256)           296448    \n",
      "_________________________________________________________________\n",
      "seq_self_attention_4 (SeqSel [(None, 50, 256), (None,  65537     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 256)               296448    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 38635)             2511275   \n",
      "=================================================================\n",
      "Total params: 7,291,833\n",
      "Trainable params: 7,291,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from random import shuffle, seed\n",
    "optimizer = Nadam()\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 model=model)\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "loss_fn = sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_song(list_all_midi, batch_music=16, start_index=0, fs=30, seq_len=50, use_tqdm=False):\n",
    "    \"\"\"\n",
    "    Generate Batch music that will be used to be input and output of the neural network\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    list_all_midi : list\n",
    "      List of midi files\n",
    "    batch_music : int\n",
    "      A number of music in one batch\n",
    "    start_index : int\n",
    "      The start index to be batched in list_all_midi\n",
    "    fs : int\n",
    "      Sampling frequency of the columns, i.e. each column is spaced apart\n",
    "        by ``1./fs`` seconds.\n",
    "    seq_len : int\n",
    "      The sequence length of the music to be input of neural network\n",
    "    use_tqdm : bool\n",
    "      Whether to use tqdm or not in the function\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    Tuple of input and target neural network\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(list_all_midi) >= batch_music\n",
    "    dict_time_notes = generate_dict_time_notes(list_all_midi, batch_music, start_index, fs, use_tqdm=use_tqdm)\n",
    "    \n",
    "    list_musics = process_notes_in_song(dict_time_notes, seq_len)\n",
    "    collected_list_input, collected_list_target = [], []\n",
    "     \n",
    "    for music in list_musics:\n",
    "        list_training, list_target = generate_input_and_target(music, seq_len)\n",
    "        collected_list_input += list_training\n",
    "        collected_list_target += list_target\n",
    "    return collected_list_input, collected_list_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "  \n",
    "  def __init__(self, epochs, note_tokenizer, sample_midi, frame_per_second, \n",
    "               batch_nnet_size, batch_song, optimizer, checkpoint, loss_fn,\n",
    "               checkpoint_prefix, total_songs, model):\n",
    "    self.epochs = epochs\n",
    "    self.note_tokenizer = note_tokenizer\n",
    "    self.sample_midi = sample_midi\n",
    "    self.frame_per_second = frame_per_second\n",
    "    self.batch_nnet_size = batch_nnet_size\n",
    "    self.batch_song = batch_song\n",
    "    self.optimizer = optimizer\n",
    "    self.checkpoint = checkpoint\n",
    "    self.loss_fn = loss_fn\n",
    "    self.checkpoint_prefix = checkpoint_prefix\n",
    "    self.total_songs = total_songs\n",
    "    self.model = model\n",
    "    \n",
    "  def train(self):\n",
    "    for epoch in tqdm_notebook(range(self.epochs),desc='epochs'):\n",
    "      # for each epochs, we shufle the list of all the datasets\n",
    "      shuffle(self.sample_midi)\n",
    "      loss_total = 0\n",
    "      steps = 0\n",
    "      steps_nnet = 0\n",
    "\n",
    "      # We will iterate all songs by self.song_size\n",
    "      for i in tqdm_notebook(range(0,self.total_songs, self.batch_song), desc='MUSIC'):\n",
    "\n",
    "        steps += 1\n",
    "        inputs_nnet_large, outputs_nnet_large = generate_batch_song(\n",
    "            self.sample_midi, self.batch_song, start_index=i, fs=self.frame_per_second, \n",
    "            seq_len=seq_len, use_tqdm=False) # We use the function that have been defined here\n",
    "        inputs_nnet_large = np.array(self.note_tokenizer.transform(inputs_nnet_large), dtype=np.int32)\n",
    "        outputs_nnet_large = np.array(self.note_tokenizer.transform(outputs_nnet_large), dtype=np.int32)\n",
    "\n",
    "        index_shuffled = np.arange(start=0, stop=len(inputs_nnet_large))\n",
    "        np.random.shuffle(index_shuffled)\n",
    "\n",
    "        for nnet_steps in tqdm_notebook(range(0,len(index_shuffled),self.batch_nnet_size)):\n",
    "          steps_nnet += 1\n",
    "          current_index = index_shuffled[nnet_steps:nnet_steps+self.batch_nnet_size]\n",
    "          inputs_nnet, outputs_nnet = inputs_nnet_large[current_index], outputs_nnet_large[current_index]\n",
    "          \n",
    "          # To make sure no exception thrown by tensorflow on autograph\n",
    "          if len(inputs_nnet) // self.batch_nnet_size != 1:\n",
    "            break\n",
    "          loss = self.train_step(inputs_nnet, outputs_nnet)\n",
    "          loss_total += tf.math.reduce_sum(loss)\n",
    "          if steps_nnet % 20 == 0:\n",
    "            print(\"epochs {} | Steps {} | total loss : {}\".format(epoch + 1, steps_nnet, loss_total))\n",
    "\n",
    "      checkpoint.save(file_prefix = self.checkpoint_prefix)\n",
    "  \n",
    "  @tf.function\n",
    "  def train_step(self, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "      prediction = self.model(inputs)\n",
    "      loss = self.loss_fn(targets, prediction)\n",
    "    gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "    self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5cc1d04bbd04ae4a39c4408c91c1166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epochs', max=4, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7c5995109c4768bf178b5de961d699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='MUSIC', max=7, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec3a7a31c164d6d96bf7b1577853dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=393), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 20 | total loss : 17157.984375\n",
      "epochs 1 | Steps 40 | total loss : 31662.171875\n",
      "epochs 1 | Steps 60 | total loss : 45972.4453125\n",
      "epochs 1 | Steps 80 | total loss : 59814.45703125\n",
      "epochs 1 | Steps 100 | total loss : 73809.8046875\n",
      "epochs 1 | Steps 120 | total loss : 87635.96875\n",
      "epochs 1 | Steps 140 | total loss : 101202.6171875\n",
      "epochs 1 | Steps 160 | total loss : 115059.640625\n",
      "epochs 1 | Steps 180 | total loss : 129019.671875\n",
      "epochs 1 | Steps 200 | total loss : 142440.53125\n",
      "epochs 1 | Steps 220 | total loss : 156046.078125\n",
      "epochs 1 | Steps 240 | total loss : 169455.734375\n",
      "epochs 1 | Steps 260 | total loss : 182954.921875\n",
      "epochs 1 | Steps 280 | total loss : 196510.28125\n",
      "epochs 1 | Steps 300 | total loss : 209766.28125\n",
      "epochs 1 | Steps 320 | total loss : 223068.15625\n",
      "epochs 1 | Steps 340 | total loss : 236473.46875\n",
      "epochs 1 | Steps 360 | total loss : 249827.625\n",
      "epochs 1 | Steps 380 | total loss : 263156.65625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2fdf3238ffc49d98b0bc2efd24f2c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=443), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 400 | total loss : 276420.1875\n",
      "epochs 1 | Steps 420 | total loss : 290842.21875\n",
      "epochs 1 | Steps 440 | total loss : 305567.15625\n",
      "epochs 1 | Steps 460 | total loss : 319905.25\n",
      "epochs 1 | Steps 480 | total loss : 334348.3125\n",
      "epochs 1 | Steps 500 | total loss : 348391.21875\n",
      "epochs 1 | Steps 520 | total loss : 362631.40625\n",
      "epochs 1 | Steps 540 | total loss : 376467.5\n",
      "epochs 1 | Steps 560 | total loss : 390691.25\n",
      "epochs 1 | Steps 580 | total loss : 404364.9375\n",
      "epochs 1 | Steps 600 | total loss : 418220.40625\n",
      "epochs 1 | Steps 620 | total loss : 432352.6875\n",
      "epochs 1 | Steps 640 | total loss : 446562.90625\n",
      "epochs 1 | Steps 660 | total loss : 460464.875\n",
      "epochs 1 | Steps 680 | total loss : 474237.65625\n",
      "epochs 1 | Steps 700 | total loss : 488149.1875\n",
      "epochs 1 | Steps 720 | total loss : 501603.875\n",
      "epochs 1 | Steps 740 | total loss : 515013.75\n",
      "epochs 1 | Steps 760 | total loss : 528713.8125\n",
      "epochs 1 | Steps 780 | total loss : 542122.875\n",
      "epochs 1 | Steps 800 | total loss : 555782.3125\n",
      "epochs 1 | Steps 820 | total loss : 569649.125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b487d1f85cf424b81c70f0a05b374cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=434), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 840 | total loss : 582693.3125\n",
      "epochs 1 | Steps 860 | total loss : 596157.0\n",
      "epochs 1 | Steps 880 | total loss : 610297.1875\n",
      "epochs 1 | Steps 900 | total loss : 623898.1875\n",
      "epochs 1 | Steps 920 | total loss : 637533.0625\n",
      "epochs 1 | Steps 940 | total loss : 651363.4375\n",
      "epochs 1 | Steps 960 | total loss : 664966.25\n",
      "epochs 1 | Steps 980 | total loss : 678622.0625\n",
      "epochs 1 | Steps 1000 | total loss : 692433.75\n",
      "epochs 1 | Steps 1020 | total loss : 705864.75\n",
      "epochs 1 | Steps 1040 | total loss : 719628.4375\n",
      "epochs 1 | Steps 1060 | total loss : 732888.125\n",
      "epochs 1 | Steps 1080 | total loss : 746511.3125\n",
      "epochs 1 | Steps 1100 | total loss : 760081.6875\n",
      "epochs 1 | Steps 1120 | total loss : 773345.0625\n",
      "epochs 1 | Steps 1140 | total loss : 786700.125\n",
      "epochs 1 | Steps 1160 | total loss : 799877.625\n",
      "epochs 1 | Steps 1180 | total loss : 813268.875\n",
      "epochs 1 | Steps 1200 | total loss : 826533.75\n",
      "epochs 1 | Steps 1220 | total loss : 839966.625\n",
      "epochs 1 | Steps 1240 | total loss : 853501.375\n",
      "epochs 1 | Steps 1260 | total loss : 866745.0625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44ce73243a44251b3f0e52284640db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=435), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 1280 | total loss : 879714.1875\n",
      "epochs 1 | Steps 1300 | total loss : 893823.0\n",
      "epochs 1 | Steps 1320 | total loss : 907884.9375\n",
      "epochs 1 | Steps 1340 | total loss : 921689.6875\n",
      "epochs 1 | Steps 1360 | total loss : 935495.125\n",
      "epochs 1 | Steps 1380 | total loss : 949262.1875\n",
      "epochs 1 | Steps 1400 | total loss : 962988.0\n",
      "epochs 1 | Steps 1420 | total loss : 976510.0625\n",
      "epochs 1 | Steps 1440 | total loss : 989929.8125\n",
      "epochs 1 | Steps 1460 | total loss : 1003135.1875\n",
      "epochs 1 | Steps 1480 | total loss : 1016555.625\n",
      "epochs 1 | Steps 1500 | total loss : 1030124.6875\n",
      "epochs 1 | Steps 1520 | total loss : 1043679.625\n",
      "epochs 1 | Steps 1540 | total loss : 1057096.375\n",
      "epochs 1 | Steps 1560 | total loss : 1070516.875\n",
      "epochs 1 | Steps 1580 | total loss : 1083991.0\n",
      "epochs 1 | Steps 1600 | total loss : 1097279.375\n",
      "epochs 1 | Steps 1620 | total loss : 1110452.75\n",
      "epochs 1 | Steps 1640 | total loss : 1123674.5\n",
      "epochs 1 | Steps 1660 | total loss : 1136883.5\n",
      "epochs 1 | Steps 1680 | total loss : 1149987.125\n",
      "epochs 1 | Steps 1700 | total loss : 1163332.25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2c155d6a904962b3d5a1a92a607f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=568), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 1720 | total loss : 1176410.25\n",
      "epochs 1 | Steps 1740 | total loss : 1190505.375\n",
      "epochs 1 | Steps 1760 | total loss : 1204234.875\n",
      "epochs 1 | Steps 1780 | total loss : 1218282.5\n",
      "epochs 1 | Steps 1800 | total loss : 1232235.0\n",
      "epochs 1 | Steps 1820 | total loss : 1246104.25\n",
      "epochs 1 | Steps 1840 | total loss : 1260128.0\n",
      "epochs 1 | Steps 1860 | total loss : 1274053.0\n",
      "epochs 1 | Steps 1880 | total loss : 1287934.125\n",
      "epochs 1 | Steps 1900 | total loss : 1301383.875\n",
      "epochs 1 | Steps 1920 | total loss : 1315177.5\n",
      "epochs 1 | Steps 1940 | total loss : 1328631.5\n",
      "epochs 1 | Steps 1960 | total loss : 1342075.625\n",
      "epochs 1 | Steps 1980 | total loss : 1355619.25\n",
      "epochs 1 | Steps 2000 | total loss : 1369081.25\n",
      "epochs 1 | Steps 2020 | total loss : 1382309.75\n",
      "epochs 1 | Steps 2040 | total loss : 1395944.125\n",
      "epochs 1 | Steps 2060 | total loss : 1409303.375\n",
      "epochs 1 | Steps 2080 | total loss : 1422659.375\n",
      "epochs 1 | Steps 2100 | total loss : 1436384.5\n",
      "epochs 1 | Steps 2120 | total loss : 1449958.375\n",
      "epochs 1 | Steps 2140 | total loss : 1463095.625\n",
      "epochs 1 | Steps 2160 | total loss : 1476449.0\n",
      "epochs 1 | Steps 2180 | total loss : 1489714.0\n",
      "epochs 1 | Steps 2200 | total loss : 1503249.0\n",
      "epochs 1 | Steps 2220 | total loss : 1516226.25\n",
      "epochs 1 | Steps 2240 | total loss : 1529581.375\n",
      "epochs 1 | Steps 2260 | total loss : 1542934.875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61d5d29cc1e4a69b862e9845f267b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=543), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 2280 | total loss : 1555956.5\n",
      "epochs 1 | Steps 2300 | total loss : 1570239.875\n",
      "epochs 1 | Steps 2320 | total loss : 1584312.375\n",
      "epochs 1 | Steps 2340 | total loss : 1598676.375\n",
      "epochs 1 | Steps 2360 | total loss : 1612772.25\n",
      "epochs 1 | Steps 2380 | total loss : 1626994.25\n",
      "epochs 1 | Steps 2400 | total loss : 1641106.875\n",
      "epochs 1 | Steps 2420 | total loss : 1655162.25\n",
      "epochs 1 | Steps 2440 | total loss : 1669152.5\n",
      "epochs 1 | Steps 2460 | total loss : 1683231.875\n",
      "epochs 1 | Steps 2480 | total loss : 1696998.625\n",
      "epochs 1 | Steps 2500 | total loss : 1711203.25\n",
      "epochs 1 | Steps 2520 | total loss : 1725626.875\n",
      "epochs 1 | Steps 2540 | total loss : 1739752.125\n",
      "epochs 1 | Steps 2560 | total loss : 1753882.875\n",
      "epochs 1 | Steps 2580 | total loss : 1768034.125\n",
      "epochs 1 | Steps 2600 | total loss : 1781917.5\n",
      "epochs 1 | Steps 2620 | total loss : 1795824.25\n",
      "epochs 1 | Steps 2640 | total loss : 1809946.75\n",
      "epochs 1 | Steps 2660 | total loss : 1823935.125\n",
      "epochs 1 | Steps 2680 | total loss : 1837629.875\n",
      "epochs 1 | Steps 2700 | total loss : 1851738.5\n",
      "epochs 1 | Steps 2720 | total loss : 1865400.625\n",
      "epochs 1 | Steps 2740 | total loss : 1879360.625\n",
      "epochs 1 | Steps 2760 | total loss : 1893332.625\n",
      "epochs 1 | Steps 2780 | total loss : 1907399.375\n",
      "epochs 1 | Steps 2800 | total loss : 1921169.625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a745bed985454f9c2d06a479a82df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=165), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 2820 | total loss : 1934571.5\n",
      "epochs 1 | Steps 2840 | total loss : 1949001.375\n",
      "epochs 1 | Steps 2860 | total loss : 1962704.625\n",
      "epochs 1 | Steps 2880 | total loss : 1976750.875\n",
      "epochs 1 | Steps 2900 | total loss : 1990473.125\n",
      "epochs 1 | Steps 2920 | total loss : 2003869.25\n",
      "epochs 1 | Steps 2940 | total loss : 2016915.0\n",
      "epochs 1 | Steps 2960 | total loss : 2030108.0\n",
      "epochs 1 | Steps 2980 | total loss : 2043192.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4377f599e35b4cb38084ff5279da2530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='MUSIC', max=7, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59acb168cf504d459225b7cb5a2d03a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=475), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 20 | total loss : 13062.263671875\n",
      "epochs 2 | Steps 40 | total loss : 26436.466796875\n",
      "epochs 2 | Steps 60 | total loss : 39192.734375\n",
      "epochs 2 | Steps 80 | total loss : 52431.89453125\n",
      "epochs 2 | Steps 100 | total loss : 65761.1953125\n",
      "epochs 2 | Steps 120 | total loss : 78785.1953125\n",
      "epochs 2 | Steps 140 | total loss : 91904.453125\n",
      "epochs 2 | Steps 160 | total loss : 104518.5625\n",
      "epochs 2 | Steps 180 | total loss : 117062.4296875\n",
      "epochs 2 | Steps 200 | total loss : 129896.015625\n",
      "epochs 2 | Steps 220 | total loss : 142643.796875\n",
      "epochs 2 | Steps 240 | total loss : 155630.78125\n",
      "epochs 2 | Steps 260 | total loss : 168632.6875\n",
      "epochs 2 | Steps 280 | total loss : 181198.46875\n",
      "epochs 2 | Steps 300 | total loss : 193824.984375\n",
      "epochs 2 | Steps 320 | total loss : 206417.828125\n",
      "epochs 2 | Steps 340 | total loss : 218895.328125\n",
      "epochs 2 | Steps 360 | total loss : 231660.390625\n",
      "epochs 2 | Steps 380 | total loss : 244497.703125\n",
      "epochs 2 | Steps 400 | total loss : 257145.640625\n",
      "epochs 2 | Steps 420 | total loss : 269654.65625\n",
      "epochs 2 | Steps 440 | total loss : 282236.1875\n",
      "epochs 2 | Steps 460 | total loss : 294719.5625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2692b463eeb847cda0ab5529429188f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=463), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 480 | total loss : 307256.4375\n",
      "epochs 2 | Steps 500 | total loss : 320651.625\n",
      "epochs 2 | Steps 520 | total loss : 334182.96875\n",
      "epochs 2 | Steps 540 | total loss : 347567.34375\n",
      "epochs 2 | Steps 560 | total loss : 361228.96875\n",
      "epochs 2 | Steps 580 | total loss : 374584.5\n",
      "epochs 2 | Steps 600 | total loss : 388033.65625\n",
      "epochs 2 | Steps 620 | total loss : 401548.3125\n",
      "epochs 2 | Steps 640 | total loss : 414772.4375\n",
      "epochs 2 | Steps 660 | total loss : 428022.875\n",
      "epochs 2 | Steps 680 | total loss : 441254.1875\n",
      "epochs 2 | Steps 700 | total loss : 454648.65625\n",
      "epochs 2 | Steps 720 | total loss : 467848.1875\n",
      "epochs 2 | Steps 740 | total loss : 481267.125\n",
      "epochs 2 | Steps 760 | total loss : 494197.4375\n",
      "epochs 2 | Steps 780 | total loss : 507310.875\n",
      "epochs 2 | Steps 800 | total loss : 520493.09375\n",
      "epochs 2 | Steps 820 | total loss : 533435.5625\n",
      "epochs 2 | Steps 840 | total loss : 546703.0625\n",
      "epochs 2 | Steps 860 | total loss : 560008.25\n",
      "epochs 2 | Steps 880 | total loss : 572928.9375\n",
      "epochs 2 | Steps 900 | total loss : 586331.0625\n",
      "epochs 2 | Steps 920 | total loss : 599309.25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc286b2f37947c680abcc0ebf785392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=385), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 940 | total loss : 611783.5\n",
      "epochs 2 | Steps 960 | total loss : 624793.6875\n",
      "epochs 2 | Steps 980 | total loss : 637651.9375\n",
      "epochs 2 | Steps 1000 | total loss : 650164.125\n",
      "epochs 2 | Steps 1020 | total loss : 662496.375\n",
      "epochs 2 | Steps 1040 | total loss : 674894.0625\n",
      "epochs 2 | Steps 1060 | total loss : 687164.9375\n",
      "epochs 2 | Steps 1080 | total loss : 699488.5625\n",
      "epochs 2 | Steps 1100 | total loss : 711811.5625\n",
      "epochs 2 | Steps 1120 | total loss : 724153.4375\n",
      "epochs 2 | Steps 1140 | total loss : 736606.75\n",
      "epochs 2 | Steps 1160 | total loss : 748696.125\n",
      "epochs 2 | Steps 1180 | total loss : 761313.125\n",
      "epochs 2 | Steps 1200 | total loss : 773607.6875\n",
      "epochs 2 | Steps 1220 | total loss : 786025.625\n",
      "epochs 2 | Steps 1240 | total loss : 798169.0625\n",
      "epochs 2 | Steps 1260 | total loss : 810349.6875\n",
      "epochs 2 | Steps 1280 | total loss : 822395.6875\n",
      "epochs 2 | Steps 1300 | total loss : 834859.125\n",
      "epochs 2 | Steps 1320 | total loss : 847003.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752e0240d96b40dbbcdd51620865fe24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=482), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 1340 | total loss : 859654.5\n",
      "epochs 2 | Steps 1360 | total loss : 873089.0\n",
      "epochs 2 | Steps 1380 | total loss : 886071.875\n",
      "epochs 2 | Steps 1400 | total loss : 899296.1875\n",
      "epochs 2 | Steps 1420 | total loss : 912411.125\n",
      "epochs 2 | Steps 1440 | total loss : 925431.1875\n",
      "epochs 2 | Steps 1460 | total loss : 938428.5625\n",
      "epochs 2 | Steps 1480 | total loss : 951314.0625\n",
      "epochs 2 | Steps 1500 | total loss : 964510.0\n",
      "epochs 2 | Steps 1520 | total loss : 977467.25\n",
      "epochs 2 | Steps 1540 | total loss : 990595.25\n",
      "epochs 2 | Steps 1560 | total loss : 1003685.4375\n",
      "epochs 2 | Steps 1580 | total loss : 1016478.1875\n",
      "epochs 2 | Steps 1600 | total loss : 1029423.0\n",
      "epochs 2 | Steps 1620 | total loss : 1042358.375\n",
      "epochs 2 | Steps 1640 | total loss : 1054970.125\n",
      "epochs 2 | Steps 1660 | total loss : 1067746.0\n",
      "epochs 2 | Steps 1680 | total loss : 1080616.75\n",
      "epochs 2 | Steps 1700 | total loss : 1093381.625\n",
      "epochs 2 | Steps 1720 | total loss : 1106430.875\n",
      "epochs 2 | Steps 1740 | total loss : 1119444.875\n",
      "epochs 2 | Steps 1760 | total loss : 1132330.75\n",
      "epochs 2 | Steps 1780 | total loss : 1145204.25\n",
      "epochs 2 | Steps 1800 | total loss : 1157763.375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7cdfbe2a9914000a4223af8192576b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=475), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 1820 | total loss : 1170743.5\n",
      "epochs 2 | Steps 1840 | total loss : 1184459.75\n",
      "epochs 2 | Steps 1860 | total loss : 1198257.875\n",
      "epochs 2 | Steps 1880 | total loss : 1211875.5\n",
      "epochs 2 | Steps 1900 | total loss : 1225244.0\n",
      "epochs 2 | Steps 1920 | total loss : 1238676.25\n",
      "epochs 2 | Steps 1940 | total loss : 1252000.0\n",
      "epochs 2 | Steps 1960 | total loss : 1265349.5\n",
      "epochs 2 | Steps 1980 | total loss : 1278759.75\n",
      "epochs 2 | Steps 2000 | total loss : 1292564.75\n",
      "epochs 2 | Steps 2020 | total loss : 1305972.75\n",
      "epochs 2 | Steps 2040 | total loss : 1319163.125\n",
      "epochs 2 | Steps 2060 | total loss : 1332309.75\n",
      "epochs 2 | Steps 2080 | total loss : 1345412.375\n",
      "epochs 2 | Steps 2100 | total loss : 1358605.0\n",
      "epochs 2 | Steps 2120 | total loss : 1371707.625\n",
      "epochs 2 | Steps 2140 | total loss : 1384912.5\n",
      "epochs 2 | Steps 2160 | total loss : 1398352.375\n",
      "epochs 2 | Steps 2180 | total loss : 1411605.625\n",
      "epochs 2 | Steps 2200 | total loss : 1424646.25\n",
      "epochs 2 | Steps 2220 | total loss : 1437844.625\n",
      "epochs 2 | Steps 2240 | total loss : 1450867.25\n",
      "epochs 2 | Steps 2260 | total loss : 1463850.125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b097a77ce24f628cca167c125cf01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=535), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 2300 | total loss : 1489904.375\n",
      "epochs 2 | Steps 2320 | total loss : 1503155.25\n",
      "epochs 2 | Steps 2340 | total loss : 1516582.0\n",
      "epochs 2 | Steps 2360 | total loss : 1529781.625\n",
      "epochs 2 | Steps 2380 | total loss : 1543209.5\n",
      "epochs 2 | Steps 2400 | total loss : 1556054.875\n",
      "epochs 2 | Steps 2420 | total loss : 1568976.25\n",
      "epochs 2 | Steps 2440 | total loss : 1581970.25\n",
      "epochs 2 | Steps 2460 | total loss : 1594988.75\n",
      "epochs 2 | Steps 2480 | total loss : 1608042.0\n",
      "epochs 2 | Steps 2500 | total loss : 1621005.25\n",
      "epochs 2 | Steps 2520 | total loss : 1634240.375\n",
      "epochs 2 | Steps 2540 | total loss : 1647275.0\n",
      "epochs 2 | Steps 2560 | total loss : 1660270.75\n",
      "epochs 2 | Steps 2580 | total loss : 1673382.125\n",
      "epochs 2 | Steps 2600 | total loss : 1686315.625\n",
      "epochs 2 | Steps 2620 | total loss : 1698688.625\n",
      "epochs 2 | Steps 2640 | total loss : 1711351.375\n",
      "epochs 2 | Steps 2660 | total loss : 1724494.0\n",
      "epochs 2 | Steps 2680 | total loss : 1737759.5\n",
      "epochs 2 | Steps 2700 | total loss : 1750464.25\n",
      "epochs 2 | Steps 2720 | total loss : 1763389.5\n",
      "epochs 2 | Steps 2740 | total loss : 1775921.625\n",
      "epochs 2 | Steps 2760 | total loss : 1788587.25\n",
      "epochs 2 | Steps 2780 | total loss : 1801231.375\n",
      "epochs 2 | Steps 2800 | total loss : 1813885.75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043c67d079d144c4b92b0de853c49ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=165), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 2820 | total loss : 1825941.125\n",
      "epochs 2 | Steps 2840 | total loss : 1838038.875\n",
      "epochs 2 | Steps 2860 | total loss : 1849496.375\n",
      "epochs 2 | Steps 2880 | total loss : 1860905.625\n",
      "epochs 2 | Steps 2900 | total loss : 1872191.25\n",
      "epochs 2 | Steps 2920 | total loss : 1883488.75\n",
      "epochs 2 | Steps 2940 | total loss : 1894726.75\n",
      "epochs 2 | Steps 2960 | total loss : 1906096.625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbcd2a4cab84e56bc50d9418daa25a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='MUSIC', max=7, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4225889b6d4c4f1599a7f320601cd650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=442), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 3 | Steps 20 | total loss : 13181.439453125\n",
      "epochs 3 | Steps 40 | total loss : 25949.244140625\n",
      "epochs 3 | Steps 60 | total loss : 38477.26171875\n",
      "epochs 3 | Steps 80 | total loss : 51145.21875\n",
      "epochs 3 | Steps 100 | total loss : 63706.859375\n",
      "epochs 3 | Steps 120 | total loss : 75801.2109375\n",
      "epochs 3 | Steps 140 | total loss : 88054.734375\n",
      "epochs 3 | Steps 160 | total loss : 100502.3125\n",
      "epochs 3 | Steps 180 | total loss : 112922.109375\n",
      "epochs 3 | Steps 200 | total loss : 125426.6640625\n",
      "epochs 3 | Steps 220 | total loss : 137552.1875\n",
      "epochs 3 | Steps 240 | total loss : 149657.640625\n",
      "epochs 3 | Steps 260 | total loss : 162293.84375\n",
      "epochs 3 | Steps 280 | total loss : 174538.734375\n",
      "epochs 3 | Steps 300 | total loss : 186826.359375\n",
      "epochs 3 | Steps 320 | total loss : 198982.71875\n",
      "epochs 3 | Steps 340 | total loss : 211496.546875\n",
      "epochs 3 | Steps 360 | total loss : 223793.578125\n",
      "epochs 3 | Steps 380 | total loss : 235909.140625\n",
      "epochs 3 | Steps 400 | total loss : 248089.328125\n",
      "epochs 3 | Steps 420 | total loss : 260105.984375\n",
      "epochs 3 | Steps 440 | total loss : 272382.4375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d8506fbe7b4a58985dd8fd377880db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=532), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 3 | Steps 460 | total loss : 284770.21875\n",
      "epochs 3 | Steps 480 | total loss : 297286.40625\n",
      "epochs 3 | Steps 500 | total loss : 309942.15625\n",
      "epochs 3 | Steps 520 | total loss : 322207.09375\n",
      "epochs 3 | Steps 540 | total loss : 334886.625\n",
      "epochs 3 | Steps 560 | total loss : 346910.15625\n",
      "epochs 3 | Steps 580 | total loss : 359363.625\n",
      "epochs 3 | Steps 600 | total loss : 371823.25\n",
      "epochs 3 | Steps 620 | total loss : 384290.8125\n",
      "epochs 3 | Steps 640 | total loss : 396558.9375\n",
      "epochs 3 | Steps 660 | total loss : 409078.1875\n",
      "epochs 3 | Steps 680 | total loss : 421373.0625\n",
      "epochs 3 | Steps 700 | total loss : 433507.125\n",
      "epochs 3 | Steps 720 | total loss : 446233.84375\n",
      "epochs 3 | Steps 740 | total loss : 458623.28125\n",
      "epochs 3 | Steps 760 | total loss : 470888.78125\n",
      "epochs 3 | Steps 780 | total loss : 483156.21875\n",
      "epochs 3 | Steps 800 | total loss : 495462.34375\n",
      "epochs 3 | Steps 820 | total loss : 507647.75\n",
      "epochs 3 | Steps 840 | total loss : 519981.625\n",
      "epochs 3 | Steps 860 | total loss : 532187.8125\n",
      "epochs 3 | Steps 880 | total loss : 544540.1875\n",
      "epochs 3 | Steps 900 | total loss : 556602.3125\n",
      "epochs 3 | Steps 920 | total loss : 568697.5625\n",
      "epochs 3 | Steps 940 | total loss : 581131.0\n",
      "epochs 3 | Steps 960 | total loss : 593126.125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57a433ec2cc4e95ac9fd518cf08afe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=485), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 3 | Steps 980 | total loss : 604990.1875\n",
      "epochs 3 | Steps 1000 | total loss : 617856.25\n",
      "epochs 3 | Steps 1020 | total loss : 630575.3125\n",
      "epochs 3 | Steps 1040 | total loss : 643100.0625\n",
      "epochs 3 | Steps 1060 | total loss : 655711.5625\n",
      "epochs 3 | Steps 1080 | total loss : 667934.875\n",
      "epochs 3 | Steps 1100 | total loss : 680637.875\n",
      "epochs 3 | Steps 1120 | total loss : 692947.5625\n",
      "epochs 3 | Steps 1140 | total loss : 705530.75\n",
      "epochs 3 | Steps 1160 | total loss : 717841.3125\n",
      "epochs 3 | Steps 1180 | total loss : 730076.875\n",
      "epochs 3 | Steps 1200 | total loss : 742486.8125\n",
      "epochs 3 | Steps 1220 | total loss : 755008.5\n",
      "epochs 3 | Steps 1240 | total loss : 767343.25\n",
      "epochs 3 | Steps 1260 | total loss : 779988.6875\n",
      "epochs 3 | Steps 1280 | total loss : 792372.625\n",
      "epochs 3 | Steps 1300 | total loss : 804411.3125\n",
      "epochs 3 | Steps 1320 | total loss : 816740.25\n",
      "epochs 3 | Steps 1340 | total loss : 828733.8125\n",
      "epochs 3 | Steps 1360 | total loss : 840865.1875\n",
      "epochs 3 | Steps 1380 | total loss : 852894.1875\n",
      "epochs 3 | Steps 1400 | total loss : 865374.75\n",
      "epochs 3 | Steps 1420 | total loss : 877380.1875\n",
      "epochs 3 | Steps 1440 | total loss : 889392.625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5ba6f616214eb0a756ba122d309fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=437), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 3 | Steps 1460 | total loss : 900924.8125\n",
      "epochs 3 | Steps 1480 | total loss : 913838.4375\n",
      "epochs 3 | Steps 1500 | total loss : 926360.6875\n",
      "epochs 3 | Steps 1520 | total loss : 938768.125\n",
      "epochs 3 | Steps 1540 | total loss : 951350.25\n",
      "epochs 3 | Steps 1560 | total loss : 963286.0625\n",
      "epochs 3 | Steps 1580 | total loss : 975456.9375\n",
      "epochs 3 | Steps 1600 | total loss : 987710.625\n",
      "epochs 3 | Steps 1620 | total loss : 999762.8125\n",
      "epochs 3 | Steps 1640 | total loss : 1012122.1875\n",
      "epochs 3 | Steps 1660 | total loss : 1024355.0\n",
      "epochs 3 | Steps 1680 | total loss : 1036374.875\n",
      "epochs 3 | Steps 1700 | total loss : 1048480.4375\n",
      "epochs 3 | Steps 1720 | total loss : 1060341.875\n",
      "epochs 3 | Steps 1740 | total loss : 1072473.25\n",
      "epochs 3 | Steps 1760 | total loss : 1084360.75\n",
      "epochs 3 | Steps 1780 | total loss : 1096072.125\n",
      "epochs 3 | Steps 1800 | total loss : 1107928.5\n",
      "epochs 3 | Steps 1820 | total loss : 1119897.75\n",
      "epochs 3 | Steps 1840 | total loss : 1131718.375\n",
      "epochs 3 | Steps 1860 | total loss : 1143327.0\n",
      "epochs 3 | Steps 1880 | total loss : 1155382.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd00720679264ea285608cf45782c4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=490), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 3 | Steps 1900 | total loss : 1166749.75\n",
      "epochs 3 | Steps 1920 | total loss : 1179536.125\n",
      "epochs 3 | Steps 1940 | total loss : 1191897.125\n",
      "epochs 3 | Steps 1960 | total loss : 1204382.5\n",
      "epochs 3 | Steps 1980 | total loss : 1216612.25\n",
      "epochs 3 | Steps 2000 | total loss : 1228885.625\n",
      "epochs 3 | Steps 2020 | total loss : 1241233.5\n",
      "epochs 3 | Steps 2040 | total loss : 1253501.625\n",
      "epochs 3 | Steps 2060 | total loss : 1265585.875\n",
      "epochs 3 | Steps 2080 | total loss : 1277817.0\n",
      "epochs 3 | Steps 2100 | total loss : 1290214.625\n",
      "epochs 3 | Steps 2120 | total loss : 1302406.0\n",
      "epochs 3 | Steps 2140 | total loss : 1314602.625\n",
      "epochs 3 | Steps 2160 | total loss : 1326801.875\n",
      "epochs 3 | Steps 2180 | total loss : 1338828.875\n",
      "epochs 3 | Steps 2200 | total loss : 1350887.125\n",
      "epochs 3 | Steps 2220 | total loss : 1363139.875\n",
      "epochs 3 | Steps 2240 | total loss : 1375314.375\n",
      "epochs 3 | Steps 2260 | total loss : 1387236.375\n",
      "epochs 3 | Steps 2280 | total loss : 1399450.875\n",
      "epochs 3 | Steps 2300 | total loss : 1411553.5\n",
      "epochs 3 | Steps 2320 | total loss : 1423537.125\n",
      "epochs 3 | Steps 2340 | total loss : 1435550.25\n",
      "epochs 3 | Steps 2360 | total loss : 1447276.5\n",
      "epochs 3 | Steps 2380 | total loss : 1459253.875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29cd2bad1fe445391e3f30e5ac11874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=472), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 3 | Steps 2400 | total loss : 1471432.625\n",
      "epochs 3 | Steps 2420 | total loss : 1484008.5\n",
      "epochs 3 | Steps 2440 | total loss : 1496804.0\n",
      "epochs 3 | Steps 2460 | total loss : 1509380.5\n",
      "epochs 3 | Steps 2480 | total loss : 1521795.0\n",
      "epochs 3 | Steps 2500 | total loss : 1534488.125\n",
      "epochs 3 | Steps 2520 | total loss : 1546713.25\n",
      "epochs 3 | Steps 2540 | total loss : 1559072.75\n",
      "epochs 3 | Steps 2560 | total loss : 1571229.25\n",
      "epochs 3 | Steps 2580 | total loss : 1583367.5\n",
      "epochs 3 | Steps 2600 | total loss : 1595516.25\n",
      "epochs 3 | Steps 2620 | total loss : 1607692.875\n",
      "epochs 3 | Steps 2640 | total loss : 1619534.625\n",
      "epochs 3 | Steps 2660 | total loss : 1631524.5\n",
      "epochs 3 | Steps 2680 | total loss : 1643528.25\n",
      "epochs 3 | Steps 2700 | total loss : 1655337.0\n",
      "epochs 3 | Steps 2720 | total loss : 1667097.875\n",
      "epochs 3 | Steps 2740 | total loss : 1679208.375\n",
      "epochs 3 | Steps 2760 | total loss : 1690990.375\n",
      "epochs 3 | Steps 2780 | total loss : 1702850.75\n",
      "epochs 3 | Steps 2800 | total loss : 1714804.625\n",
      "epochs 3 | Steps 2820 | total loss : 1726619.5\n",
      "epochs 3 | Steps 2840 | total loss : 1738223.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4244d3e9b947d5a8fd3904b5c0b9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=121), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 3 | Steps 2860 | total loss : 1749551.5\n",
      "epochs 3 | Steps 2880 | total loss : 1762460.125\n",
      "epochs 3 | Steps 2900 | total loss : 1774956.625\n",
      "epochs 3 | Steps 2920 | total loss : 1787382.125\n",
      "epochs 3 | Steps 2940 | total loss : 1799282.625\n",
      "epochs 3 | Steps 2960 | total loss : 1811083.25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2691eb01dbf646d4bee98d9c56693fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='MUSIC', max=7, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76c368cacbe40fbb56e9d797210fffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=574), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 4 | Steps 20 | total loss : 12433.9296875\n",
      "epochs 4 | Steps 40 | total loss : 24493.49609375\n",
      "epochs 4 | Steps 60 | total loss : 36138.12890625\n",
      "epochs 4 | Steps 80 | total loss : 47778.7265625\n",
      "epochs 4 | Steps 100 | total loss : 59683.421875\n",
      "epochs 4 | Steps 120 | total loss : 71748.40625\n",
      "epochs 4 | Steps 140 | total loss : 83300.390625\n",
      "epochs 4 | Steps 160 | total loss : 94971.1875\n",
      "epochs 4 | Steps 180 | total loss : 106908.1171875\n",
      "epochs 4 | Steps 200 | total loss : 118763.5703125\n",
      "epochs 4 | Steps 220 | total loss : 130389.2109375\n",
      "epochs 4 | Steps 240 | total loss : 142034.03125\n",
      "epochs 4 | Steps 260 | total loss : 153526.515625\n",
      "epochs 4 | Steps 280 | total loss : 165144.296875\n",
      "epochs 4 | Steps 300 | total loss : 176800.328125\n",
      "epochs 4 | Steps 320 | total loss : 188320.703125\n",
      "epochs 4 | Steps 340 | total loss : 199939.015625\n",
      "epochs 4 | Steps 360 | total loss : 211617.3125\n",
      "epochs 4 | Steps 380 | total loss : 223304.28125\n",
      "epochs 4 | Steps 400 | total loss : 235077.375\n",
      "epochs 4 | Steps 420 | total loss : 246510.015625\n",
      "epochs 4 | Steps 440 | total loss : 257788.140625\n",
      "epochs 4 | Steps 460 | total loss : 269226.1875\n",
      "epochs 4 | Steps 480 | total loss : 280337.1875\n",
      "epochs 4 | Steps 500 | total loss : 291646.5625\n",
      "epochs 4 | Steps 520 | total loss : 303210.625\n",
      "epochs 4 | Steps 540 | total loss : 314550.875\n",
      "epochs 4 | Steps 560 | total loss : 325883.0625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46a999e9f064751a1f7d054ec836446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=396), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 4 | Steps 580 | total loss : 337054.9375\n",
      "epochs 4 | Steps 600 | total loss : 349279.75\n",
      "epochs 4 | Steps 620 | total loss : 360887.71875\n",
      "epochs 4 | Steps 640 | total loss : 372306.4375\n",
      "epochs 4 | Steps 660 | total loss : 383884.1875\n",
      "epochs 4 | Steps 680 | total loss : 395023.09375\n",
      "epochs 4 | Steps 700 | total loss : 406229.1875\n",
      "epochs 4 | Steps 720 | total loss : 417472.65625\n",
      "epochs 4 | Steps 740 | total loss : 428399.21875\n",
      "epochs 4 | Steps 760 | total loss : 439494.9375\n",
      "epochs 4 | Steps 780 | total loss : 450509.3125\n",
      "epochs 4 | Steps 800 | total loss : 461696.53125\n",
      "epochs 4 | Steps 820 | total loss : 472653.875\n",
      "epochs 4 | Steps 840 | total loss : 483839.8125\n",
      "epochs 4 | Steps 860 | total loss : 495073.375\n",
      "epochs 4 | Steps 880 | total loss : 506146.90625\n",
      "epochs 4 | Steps 900 | total loss : 517150.78125\n",
      "epochs 4 | Steps 920 | total loss : 527771.0\n",
      "epochs 4 | Steps 940 | total loss : 538716.5\n",
      "epochs 4 | Steps 960 | total loss : 549607.4375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b782e334f9e64e3a8544eea90252bcc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=561), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 4 | Steps 980 | total loss : 560656.3125\n",
      "epochs 4 | Steps 1000 | total loss : 572649.1875\n",
      "epochs 4 | Steps 1020 | total loss : 584572.6875\n",
      "epochs 4 | Steps 1040 | total loss : 596567.25\n",
      "epochs 4 | Steps 1060 | total loss : 608396.5625\n",
      "epochs 4 | Steps 1080 | total loss : 619879.0625\n",
      "epochs 4 | Steps 1100 | total loss : 631510.8125\n",
      "epochs 4 | Steps 1120 | total loss : 643290.0\n",
      "epochs 4 | Steps 1140 | total loss : 655113.625\n",
      "epochs 4 | Steps 1160 | total loss : 666616.75\n",
      "epochs 4 | Steps 1180 | total loss : 678169.0625\n",
      "epochs 4 | Steps 1200 | total loss : 689514.375\n",
      "epochs 4 | Steps 1220 | total loss : 701055.0\n",
      "epochs 4 | Steps 1240 | total loss : 712156.5\n",
      "epochs 4 | Steps 1260 | total loss : 723838.0\n",
      "epochs 4 | Steps 1280 | total loss : 735109.8125\n",
      "epochs 4 | Steps 1300 | total loss : 746526.875\n",
      "epochs 4 | Steps 1320 | total loss : 758212.875\n",
      "epochs 4 | Steps 1340 | total loss : 769833.25\n",
      "epochs 4 | Steps 1360 | total loss : 781425.875\n",
      "epochs 4 | Steps 1380 | total loss : 792802.25\n",
      "epochs 4 | Steps 1400 | total loss : 804250.125\n",
      "epochs 4 | Steps 1420 | total loss : 815507.0\n",
      "epochs 4 | Steps 1440 | total loss : 826837.25\n",
      "epochs 4 | Steps 1460 | total loss : 838248.5625\n",
      "epochs 4 | Steps 1480 | total loss : 849707.5625\n",
      "epochs 4 | Steps 1500 | total loss : 861017.9375\n",
      "epochs 4 | Steps 1520 | total loss : 872492.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4830138f508b4fb9882983182f3f4e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=438), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 4 | Steps 1540 | total loss : 883765.625\n",
      "epochs 4 | Steps 1560 | total loss : 896241.4375\n",
      "epochs 4 | Steps 1580 | total loss : 908111.5625\n",
      "epochs 4 | Steps 1600 | total loss : 920245.6875\n",
      "epochs 4 | Steps 1620 | total loss : 931852.9375\n",
      "epochs 4 | Steps 1640 | total loss : 943570.5\n",
      "epochs 4 | Steps 1660 | total loss : 955286.0\n",
      "epochs 4 | Steps 1680 | total loss : 966797.125\n",
      "epochs 4 | Steps 1700 | total loss : 978408.9375\n",
      "epochs 4 | Steps 1720 | total loss : 989985.5625\n",
      "epochs 4 | Steps 1740 | total loss : 1001496.0625\n",
      "epochs 4 | Steps 1760 | total loss : 1012729.125\n",
      "epochs 4 | Steps 1780 | total loss : 1023968.125\n",
      "epochs 4 | Steps 1800 | total loss : 1035105.875\n",
      "epochs 4 | Steps 1820 | total loss : 1046542.9375\n",
      "epochs 4 | Steps 1840 | total loss : 1057760.25\n",
      "epochs 4 | Steps 1860 | total loss : 1068894.875\n",
      "epochs 4 | Steps 1880 | total loss : 1080307.0\n",
      "epochs 4 | Steps 1900 | total loss : 1091609.5\n",
      "epochs 4 | Steps 1920 | total loss : 1102662.5\n",
      "epochs 4 | Steps 1940 | total loss : 1113774.125\n",
      "epochs 4 | Steps 1960 | total loss : 1125135.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7d0b8696c248f19322cd98752825e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=563), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 4 | Steps 1980 | total loss : 1136877.375\n",
      "epochs 4 | Steps 2000 | total loss : 1149213.125\n",
      "epochs 4 | Steps 2020 | total loss : 1161579.75\n",
      "epochs 4 | Steps 2040 | total loss : 1173903.375\n",
      "epochs 4 | Steps 2060 | total loss : 1186014.5\n",
      "epochs 4 | Steps 2080 | total loss : 1198044.875\n",
      "epochs 4 | Steps 2100 | total loss : 1209995.25\n",
      "epochs 4 | Steps 2120 | total loss : 1221700.875\n",
      "epochs 4 | Steps 2140 | total loss : 1233553.25\n",
      "epochs 4 | Steps 2160 | total loss : 1245360.0\n",
      "epochs 4 | Steps 2180 | total loss : 1257384.125\n",
      "epochs 4 | Steps 2200 | total loss : 1269449.875\n",
      "epochs 4 | Steps 2220 | total loss : 1281523.25\n",
      "epochs 4 | Steps 2240 | total loss : 1292881.5\n",
      "epochs 4 | Steps 2260 | total loss : 1304578.375\n",
      "epochs 4 | Steps 2280 | total loss : 1316106.375\n",
      "epochs 4 | Steps 2300 | total loss : 1327644.375\n",
      "epochs 4 | Steps 2320 | total loss : 1339247.5\n",
      "epochs 4 | Steps 2340 | total loss : 1350815.125\n",
      "epochs 4 | Steps 2360 | total loss : 1362438.625\n",
      "epochs 4 | Steps 2380 | total loss : 1373778.0\n",
      "epochs 4 | Steps 2400 | total loss : 1385126.5\n",
      "epochs 4 | Steps 2420 | total loss : 1396752.875\n",
      "epochs 4 | Steps 2440 | total loss : 1408379.875\n",
      "epochs 4 | Steps 2460 | total loss : 1419643.375\n",
      "epochs 4 | Steps 2480 | total loss : 1430889.375\n",
      "epochs 4 | Steps 2500 | total loss : 1441984.375\n",
      "epochs 4 | Steps 2520 | total loss : 1453239.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3cedd446d5f4894b79cfc77de9bc781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=331), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 4 | Steps 2540 | total loss : 1464390.25\n",
      "epochs 4 | Steps 2560 | total loss : 1476085.875\n",
      "epochs 4 | Steps 2580 | total loss : 1487888.875\n",
      "epochs 4 | Steps 2600 | total loss : 1499180.125\n",
      "epochs 4 | Steps 2620 | total loss : 1510702.125\n",
      "epochs 4 | Steps 2640 | total loss : 1522059.875\n",
      "epochs 4 | Steps 2660 | total loss : 1533228.25\n",
      "epochs 4 | Steps 2680 | total loss : 1544543.625\n",
      "epochs 4 | Steps 2700 | total loss : 1555718.25\n",
      "epochs 4 | Steps 2720 | total loss : 1567049.625\n",
      "epochs 4 | Steps 2740 | total loss : 1577951.25\n",
      "epochs 4 | Steps 2760 | total loss : 1588939.875\n",
      "epochs 4 | Steps 2780 | total loss : 1599866.0\n",
      "epochs 4 | Steps 2800 | total loss : 1610876.375\n",
      "epochs 4 | Steps 2820 | total loss : 1621855.375\n",
      "epochs 4 | Steps 2840 | total loss : 1632906.125\n",
      "epochs 4 | Steps 2860 | total loss : 1643868.75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfaad8ccf6cf4aff844a2e1c7666d13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=118), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 4 | Steps 2880 | total loss : 1655025.0\n",
      "epochs 4 | Steps 2900 | total loss : 1666277.375\n",
      "epochs 4 | Steps 2920 | total loss : 1676952.5\n",
      "epochs 4 | Steps 2940 | total loss : 1687610.75\n",
      "epochs 4 | Steps 2960 | total loss : 1697723.5\n",
      "epochs 4 | Steps 2980 | total loss : 1708068.625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seq_len = 50\n",
    "EPOCHS = 4\n",
    "BATCH_SONG = 16\n",
    "BATCH_NNET_SIZE = 96\n",
    "TOTAL_SONGS = len(sample_midi)\n",
    "FRAME_PER_SECOND = 5\n",
    "\n",
    "train_class = TrainModel(EPOCHS, note_tokenizer, sample_midi, FRAME_PER_SECOND,\n",
    "                  BATCH_NNET_SIZE, BATCH_SONG, optimizer, checkpoint, loss_fn,\n",
    "                  checkpoint_prefix, TOTAL_SONGS, model)\n",
    "\n",
    "train_class.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_ep4.h5')\n",
    "pickle.dump( note_tokenizer, open( \"tokenizer.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('model_ep4.h5', custom_objects=SeqSelfAttention.get_custom_objects())\n",
    "note_tokenizer  = pickle.load( open( \"tokenizer.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_from_random(unique_notes, seq_len=50):\n",
    "  generate = np.random.randint(0,unique_notes,seq_len).tolist()\n",
    "  return generate\n",
    "    \n",
    "def generate_from_one_note(note_tokenizer, new_notes='35'):\n",
    "  generate = [note_tokenizer.notes_to_index['e'] for i in range(49)]\n",
    "  generate += [note_tokenizer.notes_to_index[new_notes]]\n",
    "  return generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piano_roll_to_pretty_midi(piano_roll, fs=100, program=0):\n",
    "    '''Convert a Piano Roll array into a PrettyMidi object\n",
    "     with a single instrument.\n",
    "    Parameters\n",
    "    ----------\n",
    "    piano_roll : np.ndarray, shape=(128,frames), dtype=int\n",
    "        Piano roll of one instrument\n",
    "    fs : int\n",
    "        Sampling frequency of the columns, i.e. each column is spaced apart\n",
    "        by ``1./fs`` seconds.\n",
    "    program : int\n",
    "        The program number of the instrument.\n",
    "    Returns\n",
    "    -------\n",
    "    midi_object : pretty_midi.PrettyMIDI\n",
    "        A pretty_midi.PrettyMIDI class instance describing\n",
    "        the piano roll.\n",
    "    '''\n",
    "    notes, frames = piano_roll.shape\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=program)\n",
    "\n",
    "    # pad 1 column of zeros so we can acknowledge inital and ending events\n",
    "    piano_roll = np.pad(piano_roll, [(0, 0), (1, 1)], 'constant')\n",
    "\n",
    "    # use changes in velocities to find note on / note off events\n",
    "    velocity_changes = np.nonzero(np.diff(piano_roll).T)\n",
    "\n",
    "    # keep track on velocities and note on times\n",
    "    prev_velocities = np.zeros(notes, dtype=int)\n",
    "    note_on_time = np.zeros(notes)\n",
    "\n",
    "    for time, note in zip(*velocity_changes):\n",
    "        # use time + 1 because of padding above\n",
    "        velocity = piano_roll[note, time + 1]\n",
    "        time = time / fs\n",
    "        if velocity > 0:\n",
    "            if prev_velocities[note] == 0:\n",
    "                note_on_time[note] = time\n",
    "                prev_velocities[note] = velocity\n",
    "        else:\n",
    "            pm_note = pretty_midi.Note(\n",
    "                velocity=prev_velocities[note],\n",
    "                pitch=note,\n",
    "                start=note_on_time[note],\n",
    "                end=time)\n",
    "            instrument.notes.append(pm_note)\n",
    "            prev_velocities[note] = 0\n",
    "    pm.instruments.append(instrument)\n",
    "    return pm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "def generate_notes(generate, model, unique_notes, max_generated=1000, seq_len=50):\n",
    "  for i in tqdm_notebook(range(max_generated), desc='genrt'):\n",
    "    test_input = np.array([generate])[:,i:i+seq_len]\n",
    "    predicted_note = model.predict(test_input)\n",
    "    random_note_pred = choice(unique_notes+1, 1, replace=False, p=predicted_note[0])\n",
    "    generate.append(random_note_pred[0])\n",
    "  return generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_midi_file_from_generated(generate, midi_file_name = \"result.mid\", start_index=49, fs=8, max_generated=1000):\n",
    "  note_string = [note_tokenizer.index_to_notes[ind_note] for ind_note in generate]\n",
    "  array_piano_roll = np.zeros((128,max_generated+1), dtype=np.int16)\n",
    "  for index, note in enumerate(note_string[start_index:]):\n",
    "    if note == 'e':\n",
    "      pass\n",
    "    else:\n",
    "      splitted_note = note.split(',')\n",
    "      for j in splitted_note:\n",
    "        array_piano_roll[int(j),index] = 1\n",
    "  generate_to_midi = piano_roll_to_pretty_midi(array_piano_roll, fs=fs)\n",
    "  print(\"Tempo {}\".format(generate_to_midi.estimate_tempo()))\n",
    "  for note in generate_to_midi.instruments[0].notes:\n",
    "    note.velocity = 100\n",
    "  generate_to_midi.write(midi_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "random0.mid\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# generate random integer values\n",
    "from random import seed\n",
    "from random import randint\n",
    "# seed random number generator\n",
    "#seed(9)\n",
    "value = randint(0, 100)\n",
    "print(value)\n",
    "name='random'+str(value)+'.mid'\n",
    "name1='one_note'+str(value)+'.mid'\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b7187c7d9e40e09ebecc611d37ec29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='genrt', max=200, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo 209.4117647058822\n"
     ]
    }
   ],
   "source": [
    "max_generate = 200\n",
    "unique_notes = note_tokenizer.unique_word\n",
    "seq_len=50\n",
    "generate = generate_from_random(unique_notes, seq_len)\n",
    "generate = generate_notes(generate, model, unique_notes, max_generate, seq_len)\n",
    "write_midi_file_from_generated(generate, name, start_index=seq_len-1, fs=7, max_generated = max_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1214bf99b7d4fc8a7798178dffa356d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='genrt', max=300, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo 236.46315789473675\n"
     ]
    }
   ],
   "source": [
    "max_generate = 300\n",
    "unique_notes = note_tokenizer.unique_word\n",
    "seq_len=50\n",
    "generate = generate_from_one_note(note_tokenizer, '72')\n",
    "generate = generate_notes(generate, model, unique_notes, max_generate, seq_len)\n",
    "write_midi_file_from_generated(generate, name1, start_index=seq_len-1, fs=8, max_generated = max_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
